{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bc6658a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "from __future__ import division\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.models import inception_v3, Inception_V3_Weights\n",
    "from torchvision.datasets.folder import default_loader, IMG_EXTENSIONS\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "import random\n",
    "from PIL import Image\n",
    "from torch.utils.data import (TensorDataset, \n",
    "                              Dataset, \n",
    "                              Subset,\n",
    "                              random_split,\n",
    "                              DataLoader,\n",
    "                              RandomSampler, \n",
    "                              SequentialSampler, \n",
    "                              )\n",
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "from models import initialize_vision_model, initialize_language_model\n",
    "from GarbageUtils import GarbageDataset, split_dataset, GarbageImageFolder, append_value\n",
    "\n",
    "import transformers\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9c079dd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from torchvision.models import (inception_v3, \n",
    "#                                 Inception_V3_Weights,\n",
    "#                                 efficientnet_b7, \n",
    "#                                 EfficientNet_B7_Weights, \n",
    "#                                 mobilenet_v2, \n",
    "#                                 MobileNet_V2_Weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "23cd2ab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_ft = mobilenet_v2(weights=MobileNet_V2_Weights.DEFAULT)\n",
    "# model_ft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c5e57284",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n",
      "PyTorch Version:  2.5.1+cu124\n",
      "Torchvision Version:  0.20.1+cu124\n",
      "Transformers Version:  4.46.3\n"
     ]
    }
   ],
   "source": [
    "print(f'Device: {device}')\n",
    "print(\"PyTorch Version: \",torch.__version__)\n",
    "print(\"Torchvision Version: \",torchvision.__version__)\n",
    "print(\"Transformers Version: \", transformers.__version__)\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3ae7957f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"./data\"\n",
    "vision_model_name = \"mobilenet_v2\"\n",
    "language_model_name = \"bert-base-uncased\"\n",
    "num_classes = 4\n",
    "batch_size = 16 #4 #32 #16\n",
    "epochs = 100\n",
    "feature_extract = True\n",
    "\n",
    "# remember to set your CSV_NAME and PATH to save model weights\n",
    "learning_rate = 0.001\n",
    "CSV_NAME = \"100epochs_lr_0_001_mobilenet_v2_bs16.csv\"\n",
    "PATH = \"100epochs_lr_0_001_mobilenet_v2_bs16.pth\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0352ad2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if language_model_name == \"bert-base-uncased\":\n",
    "#     out_features = 2052"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3713b9b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "if vision_model_name == \"inception\":\n",
    "    out_features = 2052\n",
    "elif vision_model_name == \"efficientnet_b7\":\n",
    "    out_features = 2564\n",
    "elif vision_model_name == \"mobilenet_v2\":\n",
    "    out_features = 1284"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "475fee90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing MobileNetV2 with weights=MobileNet_V2_Weights.DEFAULT ...\n",
      "Input size = 224\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Initializing Bert-Base-Uncased...\n"
     ]
    }
   ],
   "source": [
    "vision_model, input_size = initialize_vision_model(vision_model_name, num_classes, feature_extract, multimodal=True)\n",
    "language_model, tokenizer = initialize_language_model(language_model_name, num_classes, multimodal=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "44fb3f74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MobileNetV2(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2dNormActivation(\n",
       "      (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU6(inplace=True)\n",
       "    )\n",
       "    (1): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (2): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=96, bias=False)\n",
       "          (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (3): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=144, bias=False)\n",
       "          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (4): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=144, bias=False)\n",
       "          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (5): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
       "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (6): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
       "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (7): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=192, bias=False)\n",
       "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (8): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
       "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (9): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
       "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (10): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
       "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (11): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
       "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (12): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
       "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (13): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
       "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (14): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=576, bias=False)\n",
       "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(576, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (15): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
       "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (16): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
       "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (17): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
       "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(960, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (18): Conv2dNormActivation(\n",
       "      (0): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(1280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU6(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (classifier): Sequential(\n",
       "    (0): Dropout(p=0.2, inplace=False)\n",
       "    (1): Identity()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vision_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a08e0949",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_image(path):\n",
    "    try:\n",
    "        im = Image.open(path)\n",
    "        return True\n",
    "    except:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9cd091b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_dataset = GarbageImageFolder(data_dir, is_valid_file=validate_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3ff24312",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset GarbageImageFolder\n",
       "    Number of datapoints: 5312\n",
       "    Root location: ./data"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b8d040c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['black', 'blue', 'green', 'other']\n",
      "Num of Classes: 4\n"
     ]
    }
   ],
   "source": [
    "classes =  image_dataset.classes\n",
    "num_classes = len(classes)\n",
    "print(classes)\n",
    "print(f'Num of Classes: {num_classes}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9d92b7c8",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'black': 0, 'blue': 1, 'green': 2, 'other': 3}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_dataset.class_to_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "68a38ba8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(<PIL.Image.Image image mode=RGB size=800x800 at 0x255D04A1CD0>, 0),\n",
       " (<PIL.Image.Image image mode=RGB size=800x800 at 0x255CE0360A0>, 0),\n",
       " (<PIL.Image.Image image mode=RGB size=800x800 at 0x255CE0369D0>, 0),\n",
       " (<PIL.Image.Image image mode=RGB size=800x800 at 0x255C1DFC5B0>, 0),\n",
       " (<PIL.Image.Image image mode=RGB size=800x800 at 0x255C0E1EA90>, 0),\n",
       " (<PIL.Image.Image image mode=RGB size=1734x1301 at 0x255C0E1EB50>, 0)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = slice(-3, -1)\n",
    "image_dataset[0:6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9180cfb0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(<PIL.Image.Image image mode=RGB size=1155x1600 at 0x255D04A3580>, 3),\n",
       " (<PIL.Image.Image image mode=RGB size=2615x3044 at 0x255D04A3640>, 3)]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_dataset[a]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3092235b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_set, val_set, test_set = split_dataset(image_dataset.imgs, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e75ad41e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "Train set size: 3187\n",
      "Val set size: 1062\n",
      "Test set size: 1062\n"
     ]
    }
   ],
   "source": [
    "def get_dataloaders(input_size, train_set, val_set, test_set):\n",
    "    from torchvision import datasets, transforms\n",
    "    data_transforms = {\n",
    "        'train': transforms.Compose([\n",
    "            transforms.RandomResizedCrop(input_size),\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "        ]),\n",
    "        'val': transforms.Compose([\n",
    "            transforms.Resize(input_size),\n",
    "            transforms.CenterCrop(input_size),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "        ]),\n",
    "    }\n",
    "    \n",
    "    train_set = GarbageDataset(train_set, is_subset=False, transform=data_transforms['train'])\n",
    "    val_set = GarbageDataset(val_set,  is_subset=False, transform=data_transforms['val'])\n",
    "    test_set = GarbageDataset(test_set,  is_subset=False, transform=data_transforms['val'])\n",
    "    \n",
    "    print(\"Loading data...\")\n",
    "    print(f'Train set size: {len(train_set)}')\n",
    "    print(f'Val set size: {len(val_set)}')\n",
    "    print(f'Test set size: {len(test_set)}')\n",
    "    \n",
    "    dataloaders_dict = {\n",
    "        'train': DataLoader(train_set, batch_size = batch_size, shuffle=True, num_workers=4, drop_last=True),\n",
    "        'val': DataLoader(val_set, batch_size = batch_size, shuffle=False, num_workers=4, drop_last=True)\n",
    "    }\n",
    "    \n",
    "    test_dataloader = DataLoader(test_set, batch_size=batch_size, shuffle=False, num_workers=4, drop_last=True)\n",
    "    \n",
    "#     print(\"Loading Datasets and Initializing DataLoaders...\")\n",
    "    return test_dataloader, dataloaders_dict\n",
    "\n",
    "test_dataloader, dataloaders_dict = get_dataloaders(input_size, train_set, val_set, test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1f6eb5c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiModalGarbageModel(torch.nn.Module):\n",
    "    def __init__(self, num_classes, text_module, vision_module, text_module_name, vision_module_name,\n",
    "                 out_features_combined, dropout_p=None):\n",
    "        super(MultiModalGarbageModel, self).__init__()\n",
    "        self.text_module = text_module\n",
    "        self.vision_module = vision_module\n",
    "        self.text_module_name = text_module_name\n",
    "        self.vision_module_name = vision_module_name\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(out_features_combined, int(out_features_combined/2)),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(int(out_features_combined/2), num_classes),\n",
    "        )\n",
    "\n",
    "    def forward(self, vision_data, text_data, attention_mask):\n",
    "        text_out, vision_out = 0, 0\n",
    "        \n",
    "        # get output from vision model\n",
    "        if self.vision_module_name == \"inception\":\n",
    "            self.vision_module.aux_logits = False\n",
    "            vision_out = self.vision_module(vision_data)\n",
    "        else:\n",
    "            vision_out = self.vision_module(vision_data)\n",
    "\n",
    "        # get output from text model    \n",
    "        if self.text_module_name == \"bert-base-uncased\":\n",
    "            out = self.text_module(text_data, attention_mask)\n",
    "            text_out = out[0]\n",
    "        else:\n",
    "            text_out = self.text_module(text_data, attention_mask)\n",
    "            \n",
    "        combined = torch.cat((vision_out, text_out), dim=1)\n",
    "        combined = combined.view(combined.size(0), -1)\n",
    "        logits = self.linear_relu_stack(combined)\n",
    "#         combined = self.fc(combined)\n",
    "        \n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b9f66601",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MultiModalGarbageModel(num_classes, language_model, vision_model, language_model_name,\n",
    "                                          vision_model_name, out_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "849c65b5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c661f8b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, dataloaders, criterion, optimizer, epochs=25, is_inception=False, result_dict=None):\n",
    "    since = time.time()\n",
    "    \n",
    "    val_acc_history = list()\n",
    "    \n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "    \n",
    "    for epoch in range(1, epochs+1):\n",
    "#         print(f'Epoch {epoch+1}/{epochs}')\n",
    "#         print(\"-\" * 10)\n",
    "        \n",
    "        for phase in [\"train\", \"val\"]:\n",
    "            if phase == \"train\":\n",
    "                model.train()\n",
    "            else:\n",
    "                model.eval()\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "            \n",
    "            #Iterate over the data # image_file, label, input_ids, attention_mask, file_name\n",
    "            for inputs, labels, in_ids, att_mask in dataloaders[phase]:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "                in_ids = in_ids.to(device)\n",
    "                att_mask = att_mask.to(device)\n",
    "                \n",
    "                optimizer.zero_grad() # to zero the parameter gradients\n",
    "                \n",
    "                # forward, track history if only in train mode\n",
    "                with torch.set_grad_enabled(phase == \"train\"):\n",
    "                    outputs = model(inputs, in_ids, att_mask)\n",
    "                    loss = criterion(outputs, labels)\n",
    "#                     if is_inception and phase == \"train\":\n",
    "#                         outputs, aux_outputs = model(inputs)\n",
    "#                         loss1 = criterion(outputs, labels)\n",
    "#                         loss2 = criterion(aux_outputs, labels)\n",
    "#                         loss = loss1 + 0.4*loss2\n",
    "#                     else:\n",
    "#                         outputs = model(inputs)\n",
    "#                         loss = criterion(outputs, labels)\n",
    "                    \n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    \n",
    "                    # backward, optimize only if in train mode\n",
    "                    if phase == \"train\":\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "                        \n",
    "                # statistics\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "                \n",
    "            epoch_loss = running_loss / len(dataloaders[phase].dataset)\n",
    "            epoch_acc = running_corrects.double() / len(dataloaders[phase].dataset)\n",
    "            \n",
    "#             print(f'{phase} Loss: {epoch_loss} Accuracy: {epoch_acc}')\n",
    "            print('-' * 59)\n",
    "            print('| Epoch {:3d}/{:3d} | {} Loss: {:8.3f} | {} Accuracy {:8.3f} |'.format(\n",
    "                epoch, epochs, phase, epoch_loss, phase, epoch_acc))\n",
    "            print('-' * 59)\n",
    "            \n",
    "            if result_dict is not None:\n",
    "                append_value(result_dict, \"Epoch\", epoch)\n",
    "                append_value(result_dict, phase+\" Accuracy\", epoch_acc)\n",
    "                append_value(result_dict, phase+\" Loss\", epoch_loss)\n",
    "            \n",
    "            # deepcopy the model\n",
    "            if phase == 'val' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "            if phase == 'val':\n",
    "                val_acc_history.append(epoch_acc)\n",
    "        print()\n",
    "        \n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training Complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best Validation Accuracy: {:.04f}'.format(best_acc))\n",
    "    \n",
    "    model.load_state_dict(best_model_wts)\n",
    "    \n",
    "    return model, val_acc_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "87699025",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters to learn:\n",
      "\t text_module.bert.embeddings.word_embeddings.weight\n",
      "\t text_module.bert.embeddings.position_embeddings.weight\n",
      "\t text_module.bert.embeddings.token_type_embeddings.weight\n",
      "\t text_module.bert.embeddings.LayerNorm.weight\n",
      "\t text_module.bert.embeddings.LayerNorm.bias\n",
      "\t text_module.bert.encoder.layer.0.attention.self.query.weight\n",
      "\t text_module.bert.encoder.layer.0.attention.self.query.bias\n",
      "\t text_module.bert.encoder.layer.0.attention.self.key.weight\n",
      "\t text_module.bert.encoder.layer.0.attention.self.key.bias\n",
      "\t text_module.bert.encoder.layer.0.attention.self.value.weight\n",
      "\t text_module.bert.encoder.layer.0.attention.self.value.bias\n",
      "\t text_module.bert.encoder.layer.0.attention.output.dense.weight\n",
      "\t text_module.bert.encoder.layer.0.attention.output.dense.bias\n",
      "\t text_module.bert.encoder.layer.0.attention.output.LayerNorm.weight\n",
      "\t text_module.bert.encoder.layer.0.attention.output.LayerNorm.bias\n",
      "\t text_module.bert.encoder.layer.0.intermediate.dense.weight\n",
      "\t text_module.bert.encoder.layer.0.intermediate.dense.bias\n",
      "\t text_module.bert.encoder.layer.0.output.dense.weight\n",
      "\t text_module.bert.encoder.layer.0.output.dense.bias\n",
      "\t text_module.bert.encoder.layer.0.output.LayerNorm.weight\n",
      "\t text_module.bert.encoder.layer.0.output.LayerNorm.bias\n",
      "\t text_module.bert.encoder.layer.1.attention.self.query.weight\n",
      "\t text_module.bert.encoder.layer.1.attention.self.query.bias\n",
      "\t text_module.bert.encoder.layer.1.attention.self.key.weight\n",
      "\t text_module.bert.encoder.layer.1.attention.self.key.bias\n",
      "\t text_module.bert.encoder.layer.1.attention.self.value.weight\n",
      "\t text_module.bert.encoder.layer.1.attention.self.value.bias\n",
      "\t text_module.bert.encoder.layer.1.attention.output.dense.weight\n",
      "\t text_module.bert.encoder.layer.1.attention.output.dense.bias\n",
      "\t text_module.bert.encoder.layer.1.attention.output.LayerNorm.weight\n",
      "\t text_module.bert.encoder.layer.1.attention.output.LayerNorm.bias\n",
      "\t text_module.bert.encoder.layer.1.intermediate.dense.weight\n",
      "\t text_module.bert.encoder.layer.1.intermediate.dense.bias\n",
      "\t text_module.bert.encoder.layer.1.output.dense.weight\n",
      "\t text_module.bert.encoder.layer.1.output.dense.bias\n",
      "\t text_module.bert.encoder.layer.1.output.LayerNorm.weight\n",
      "\t text_module.bert.encoder.layer.1.output.LayerNorm.bias\n",
      "\t text_module.bert.encoder.layer.2.attention.self.query.weight\n",
      "\t text_module.bert.encoder.layer.2.attention.self.query.bias\n",
      "\t text_module.bert.encoder.layer.2.attention.self.key.weight\n",
      "\t text_module.bert.encoder.layer.2.attention.self.key.bias\n",
      "\t text_module.bert.encoder.layer.2.attention.self.value.weight\n",
      "\t text_module.bert.encoder.layer.2.attention.self.value.bias\n",
      "\t text_module.bert.encoder.layer.2.attention.output.dense.weight\n",
      "\t text_module.bert.encoder.layer.2.attention.output.dense.bias\n",
      "\t text_module.bert.encoder.layer.2.attention.output.LayerNorm.weight\n",
      "\t text_module.bert.encoder.layer.2.attention.output.LayerNorm.bias\n",
      "\t text_module.bert.encoder.layer.2.intermediate.dense.weight\n",
      "\t text_module.bert.encoder.layer.2.intermediate.dense.bias\n",
      "\t text_module.bert.encoder.layer.2.output.dense.weight\n",
      "\t text_module.bert.encoder.layer.2.output.dense.bias\n",
      "\t text_module.bert.encoder.layer.2.output.LayerNorm.weight\n",
      "\t text_module.bert.encoder.layer.2.output.LayerNorm.bias\n",
      "\t text_module.bert.encoder.layer.3.attention.self.query.weight\n",
      "\t text_module.bert.encoder.layer.3.attention.self.query.bias\n",
      "\t text_module.bert.encoder.layer.3.attention.self.key.weight\n",
      "\t text_module.bert.encoder.layer.3.attention.self.key.bias\n",
      "\t text_module.bert.encoder.layer.3.attention.self.value.weight\n",
      "\t text_module.bert.encoder.layer.3.attention.self.value.bias\n",
      "\t text_module.bert.encoder.layer.3.attention.output.dense.weight\n",
      "\t text_module.bert.encoder.layer.3.attention.output.dense.bias\n",
      "\t text_module.bert.encoder.layer.3.attention.output.LayerNorm.weight\n",
      "\t text_module.bert.encoder.layer.3.attention.output.LayerNorm.bias\n",
      "\t text_module.bert.encoder.layer.3.intermediate.dense.weight\n",
      "\t text_module.bert.encoder.layer.3.intermediate.dense.bias\n",
      "\t text_module.bert.encoder.layer.3.output.dense.weight\n",
      "\t text_module.bert.encoder.layer.3.output.dense.bias\n",
      "\t text_module.bert.encoder.layer.3.output.LayerNorm.weight\n",
      "\t text_module.bert.encoder.layer.3.output.LayerNorm.bias\n",
      "\t text_module.bert.encoder.layer.4.attention.self.query.weight\n",
      "\t text_module.bert.encoder.layer.4.attention.self.query.bias\n",
      "\t text_module.bert.encoder.layer.4.attention.self.key.weight\n",
      "\t text_module.bert.encoder.layer.4.attention.self.key.bias\n",
      "\t text_module.bert.encoder.layer.4.attention.self.value.weight\n",
      "\t text_module.bert.encoder.layer.4.attention.self.value.bias\n",
      "\t text_module.bert.encoder.layer.4.attention.output.dense.weight\n",
      "\t text_module.bert.encoder.layer.4.attention.output.dense.bias\n",
      "\t text_module.bert.encoder.layer.4.attention.output.LayerNorm.weight\n",
      "\t text_module.bert.encoder.layer.4.attention.output.LayerNorm.bias\n",
      "\t text_module.bert.encoder.layer.4.intermediate.dense.weight\n",
      "\t text_module.bert.encoder.layer.4.intermediate.dense.bias\n",
      "\t text_module.bert.encoder.layer.4.output.dense.weight\n",
      "\t text_module.bert.encoder.layer.4.output.dense.bias\n",
      "\t text_module.bert.encoder.layer.4.output.LayerNorm.weight\n",
      "\t text_module.bert.encoder.layer.4.output.LayerNorm.bias\n",
      "\t text_module.bert.encoder.layer.5.attention.self.query.weight\n",
      "\t text_module.bert.encoder.layer.5.attention.self.query.bias\n",
      "\t text_module.bert.encoder.layer.5.attention.self.key.weight\n",
      "\t text_module.bert.encoder.layer.5.attention.self.key.bias\n",
      "\t text_module.bert.encoder.layer.5.attention.self.value.weight\n",
      "\t text_module.bert.encoder.layer.5.attention.self.value.bias\n",
      "\t text_module.bert.encoder.layer.5.attention.output.dense.weight\n",
      "\t text_module.bert.encoder.layer.5.attention.output.dense.bias\n",
      "\t text_module.bert.encoder.layer.5.attention.output.LayerNorm.weight\n",
      "\t text_module.bert.encoder.layer.5.attention.output.LayerNorm.bias\n",
      "\t text_module.bert.encoder.layer.5.intermediate.dense.weight\n",
      "\t text_module.bert.encoder.layer.5.intermediate.dense.bias\n",
      "\t text_module.bert.encoder.layer.5.output.dense.weight\n",
      "\t text_module.bert.encoder.layer.5.output.dense.bias\n",
      "\t text_module.bert.encoder.layer.5.output.LayerNorm.weight\n",
      "\t text_module.bert.encoder.layer.5.output.LayerNorm.bias\n",
      "\t text_module.bert.encoder.layer.6.attention.self.query.weight\n",
      "\t text_module.bert.encoder.layer.6.attention.self.query.bias\n",
      "\t text_module.bert.encoder.layer.6.attention.self.key.weight\n",
      "\t text_module.bert.encoder.layer.6.attention.self.key.bias\n",
      "\t text_module.bert.encoder.layer.6.attention.self.value.weight\n",
      "\t text_module.bert.encoder.layer.6.attention.self.value.bias\n",
      "\t text_module.bert.encoder.layer.6.attention.output.dense.weight\n",
      "\t text_module.bert.encoder.layer.6.attention.output.dense.bias\n",
      "\t text_module.bert.encoder.layer.6.attention.output.LayerNorm.weight\n",
      "\t text_module.bert.encoder.layer.6.attention.output.LayerNorm.bias\n",
      "\t text_module.bert.encoder.layer.6.intermediate.dense.weight\n",
      "\t text_module.bert.encoder.layer.6.intermediate.dense.bias\n",
      "\t text_module.bert.encoder.layer.6.output.dense.weight\n",
      "\t text_module.bert.encoder.layer.6.output.dense.bias\n",
      "\t text_module.bert.encoder.layer.6.output.LayerNorm.weight\n",
      "\t text_module.bert.encoder.layer.6.output.LayerNorm.bias\n",
      "\t text_module.bert.encoder.layer.7.attention.self.query.weight\n",
      "\t text_module.bert.encoder.layer.7.attention.self.query.bias\n",
      "\t text_module.bert.encoder.layer.7.attention.self.key.weight\n",
      "\t text_module.bert.encoder.layer.7.attention.self.key.bias\n",
      "\t text_module.bert.encoder.layer.7.attention.self.value.weight\n",
      "\t text_module.bert.encoder.layer.7.attention.self.value.bias\n",
      "\t text_module.bert.encoder.layer.7.attention.output.dense.weight\n",
      "\t text_module.bert.encoder.layer.7.attention.output.dense.bias\n",
      "\t text_module.bert.encoder.layer.7.attention.output.LayerNorm.weight\n",
      "\t text_module.bert.encoder.layer.7.attention.output.LayerNorm.bias\n",
      "\t text_module.bert.encoder.layer.7.intermediate.dense.weight\n",
      "\t text_module.bert.encoder.layer.7.intermediate.dense.bias\n",
      "\t text_module.bert.encoder.layer.7.output.dense.weight\n",
      "\t text_module.bert.encoder.layer.7.output.dense.bias\n",
      "\t text_module.bert.encoder.layer.7.output.LayerNorm.weight\n",
      "\t text_module.bert.encoder.layer.7.output.LayerNorm.bias\n",
      "\t text_module.bert.encoder.layer.8.attention.self.query.weight\n",
      "\t text_module.bert.encoder.layer.8.attention.self.query.bias\n",
      "\t text_module.bert.encoder.layer.8.attention.self.key.weight\n",
      "\t text_module.bert.encoder.layer.8.attention.self.key.bias\n",
      "\t text_module.bert.encoder.layer.8.attention.self.value.weight\n",
      "\t text_module.bert.encoder.layer.8.attention.self.value.bias\n",
      "\t text_module.bert.encoder.layer.8.attention.output.dense.weight\n",
      "\t text_module.bert.encoder.layer.8.attention.output.dense.bias\n",
      "\t text_module.bert.encoder.layer.8.attention.output.LayerNorm.weight\n",
      "\t text_module.bert.encoder.layer.8.attention.output.LayerNorm.bias\n",
      "\t text_module.bert.encoder.layer.8.intermediate.dense.weight\n",
      "\t text_module.bert.encoder.layer.8.intermediate.dense.bias\n",
      "\t text_module.bert.encoder.layer.8.output.dense.weight\n",
      "\t text_module.bert.encoder.layer.8.output.dense.bias\n",
      "\t text_module.bert.encoder.layer.8.output.LayerNorm.weight\n",
      "\t text_module.bert.encoder.layer.8.output.LayerNorm.bias\n",
      "\t text_module.bert.encoder.layer.9.attention.self.query.weight\n",
      "\t text_module.bert.encoder.layer.9.attention.self.query.bias\n",
      "\t text_module.bert.encoder.layer.9.attention.self.key.weight\n",
      "\t text_module.bert.encoder.layer.9.attention.self.key.bias\n",
      "\t text_module.bert.encoder.layer.9.attention.self.value.weight\n",
      "\t text_module.bert.encoder.layer.9.attention.self.value.bias\n",
      "\t text_module.bert.encoder.layer.9.attention.output.dense.weight\n",
      "\t text_module.bert.encoder.layer.9.attention.output.dense.bias\n",
      "\t text_module.bert.encoder.layer.9.attention.output.LayerNorm.weight\n",
      "\t text_module.bert.encoder.layer.9.attention.output.LayerNorm.bias\n",
      "\t text_module.bert.encoder.layer.9.intermediate.dense.weight\n",
      "\t text_module.bert.encoder.layer.9.intermediate.dense.bias\n",
      "\t text_module.bert.encoder.layer.9.output.dense.weight\n",
      "\t text_module.bert.encoder.layer.9.output.dense.bias\n",
      "\t text_module.bert.encoder.layer.9.output.LayerNorm.weight\n",
      "\t text_module.bert.encoder.layer.9.output.LayerNorm.bias\n",
      "\t text_module.bert.encoder.layer.10.attention.self.query.weight\n",
      "\t text_module.bert.encoder.layer.10.attention.self.query.bias\n",
      "\t text_module.bert.encoder.layer.10.attention.self.key.weight\n",
      "\t text_module.bert.encoder.layer.10.attention.self.key.bias\n",
      "\t text_module.bert.encoder.layer.10.attention.self.value.weight\n",
      "\t text_module.bert.encoder.layer.10.attention.self.value.bias\n",
      "\t text_module.bert.encoder.layer.10.attention.output.dense.weight\n",
      "\t text_module.bert.encoder.layer.10.attention.output.dense.bias\n",
      "\t text_module.bert.encoder.layer.10.attention.output.LayerNorm.weight\n",
      "\t text_module.bert.encoder.layer.10.attention.output.LayerNorm.bias\n",
      "\t text_module.bert.encoder.layer.10.intermediate.dense.weight\n",
      "\t text_module.bert.encoder.layer.10.intermediate.dense.bias\n",
      "\t text_module.bert.encoder.layer.10.output.dense.weight\n",
      "\t text_module.bert.encoder.layer.10.output.dense.bias\n",
      "\t text_module.bert.encoder.layer.10.output.LayerNorm.weight\n",
      "\t text_module.bert.encoder.layer.10.output.LayerNorm.bias\n",
      "\t text_module.bert.encoder.layer.11.attention.self.query.weight\n",
      "\t text_module.bert.encoder.layer.11.attention.self.query.bias\n",
      "\t text_module.bert.encoder.layer.11.attention.self.key.weight\n",
      "\t text_module.bert.encoder.layer.11.attention.self.key.bias\n",
      "\t text_module.bert.encoder.layer.11.attention.self.value.weight\n",
      "\t text_module.bert.encoder.layer.11.attention.self.value.bias\n",
      "\t text_module.bert.encoder.layer.11.attention.output.dense.weight\n",
      "\t text_module.bert.encoder.layer.11.attention.output.dense.bias\n",
      "\t text_module.bert.encoder.layer.11.attention.output.LayerNorm.weight\n",
      "\t text_module.bert.encoder.layer.11.attention.output.LayerNorm.bias\n",
      "\t text_module.bert.encoder.layer.11.intermediate.dense.weight\n",
      "\t text_module.bert.encoder.layer.11.intermediate.dense.bias\n",
      "\t text_module.bert.encoder.layer.11.output.dense.weight\n",
      "\t text_module.bert.encoder.layer.11.output.dense.bias\n",
      "\t text_module.bert.encoder.layer.11.output.LayerNorm.weight\n",
      "\t text_module.bert.encoder.layer.11.output.LayerNorm.bias\n",
      "\t text_module.bert.pooler.dense.weight\n",
      "\t text_module.bert.pooler.dense.bias\n",
      "\t text_module.classifier.weight\n",
      "\t text_module.classifier.bias\n",
      "\t linear_relu_stack.0.weight\n",
      "\t linear_relu_stack.0.bias\n",
      "\t linear_relu_stack.2.weight\n",
      "\t linear_relu_stack.2.bias\n"
     ]
    }
   ],
   "source": [
    "# send model to device: gpu or cpu\n",
    "model = model.to(device)\n",
    "\n",
    "params_to_update = model.parameters()\n",
    "print(\"Parameters to learn:\")\n",
    "if feature_extract:\n",
    "    params_to_update = list()\n",
    "    for name, param in model.named_parameters():\n",
    "        if param.requires_grad == True:\n",
    "            params_to_update.append(param)\n",
    "            print(\"\\t\", name)\n",
    "else:\n",
    "    for name, param in model.named_parameters():\n",
    "        if param.requires_grad == True:\n",
    "            print(\"\\t\", name)\n",
    "            \n",
    "optimizer_ft = optim.SGD(params_to_update, lr=learning_rate, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "dcfbc3ac",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------------------\n",
      "| Epoch   1/100 | train Loss:    1.256 | train Accuracy    0.425 |\n",
      "-----------------------------------------------------------\n",
      "-----------------------------------------------------------\n",
      "| Epoch   1/100 | val Loss:    1.155 | val Accuracy    0.494 |\n",
      "-----------------------------------------------------------\n",
      "\n",
      "-----------------------------------------------------------\n",
      "| Epoch   2/100 | train Loss:    1.112 | train Accuracy    0.543 |\n",
      "-----------------------------------------------------------\n",
      "-----------------------------------------------------------\n",
      "| Epoch   2/100 | val Loss:    1.007 | val Accuracy    0.582 |\n",
      "-----------------------------------------------------------\n",
      "\n",
      "-----------------------------------------------------------\n",
      "| Epoch   3/100 | train Loss:    0.989 | train Accuracy    0.601 |\n",
      "-----------------------------------------------------------\n",
      "-----------------------------------------------------------\n",
      "| Epoch   3/100 | val Loss:    0.862 | val Accuracy    0.680 |\n",
      "-----------------------------------------------------------\n",
      "\n",
      "-----------------------------------------------------------\n",
      "| Epoch   4/100 | train Loss:    0.946 | train Accuracy    0.617 |\n",
      "-----------------------------------------------------------\n",
      "-----------------------------------------------------------\n",
      "| Epoch   4/100 | val Loss:    0.869 | val Accuracy    0.660 |\n",
      "-----------------------------------------------------------\n",
      "\n",
      "-----------------------------------------------------------\n",
      "| Epoch   5/100 | train Loss:    0.908 | train Accuracy    0.632 |\n",
      "-----------------------------------------------------------\n",
      "-----------------------------------------------------------\n",
      "| Epoch   5/100 | val Loss:    0.841 | val Accuracy    0.669 |\n",
      "-----------------------------------------------------------\n",
      "\n",
      "-----------------------------------------------------------\n",
      "| Epoch   6/100 | train Loss:    0.885 | train Accuracy    0.641 |\n",
      "-----------------------------------------------------------\n",
      "-----------------------------------------------------------\n",
      "| Epoch   6/100 | val Loss:    0.823 | val Accuracy    0.673 |\n",
      "-----------------------------------------------------------\n",
      "\n",
      "-----------------------------------------------------------\n",
      "| Epoch   7/100 | train Loss:    0.880 | train Accuracy    0.639 |\n",
      "-----------------------------------------------------------\n",
      "-----------------------------------------------------------\n",
      "| Epoch   7/100 | val Loss:    0.812 | val Accuracy    0.679 |\n",
      "-----------------------------------------------------------\n",
      "\n",
      "-----------------------------------------------------------\n",
      "| Epoch   8/100 | train Loss:    0.871 | train Accuracy    0.654 |\n",
      "-----------------------------------------------------------\n",
      "-----------------------------------------------------------\n",
      "| Epoch   8/100 | val Loss:    0.801 | val Accuracy    0.679 |\n",
      "-----------------------------------------------------------\n",
      "\n",
      "-----------------------------------------------------------\n",
      "| Epoch   9/100 | train Loss:    0.852 | train Accuracy    0.663 |\n",
      "-----------------------------------------------------------\n",
      "-----------------------------------------------------------\n",
      "| Epoch   9/100 | val Loss:    0.788 | val Accuracy    0.685 |\n",
      "-----------------------------------------------------------\n",
      "\n",
      "-----------------------------------------------------------\n",
      "| Epoch  10/100 | train Loss:    0.844 | train Accuracy    0.658 |\n",
      "-----------------------------------------------------------\n",
      "-----------------------------------------------------------\n",
      "| Epoch  10/100 | val Loss:    0.786 | val Accuracy    0.675 |\n",
      "-----------------------------------------------------------\n",
      "\n",
      "-----------------------------------------------------------\n",
      "| Epoch  11/100 | train Loss:    0.849 | train Accuracy    0.653 |\n",
      "-----------------------------------------------------------\n",
      "-----------------------------------------------------------\n",
      "| Epoch  11/100 | val Loss:    0.781 | val Accuracy    0.679 |\n",
      "-----------------------------------------------------------\n",
      "\n",
      "-----------------------------------------------------------\n",
      "| Epoch  12/100 | train Loss:    0.824 | train Accuracy    0.667 |\n",
      "-----------------------------------------------------------\n",
      "-----------------------------------------------------------\n",
      "| Epoch  12/100 | val Loss:    0.770 | val Accuracy    0.687 |\n",
      "-----------------------------------------------------------\n",
      "\n",
      "-----------------------------------------------------------\n",
      "| Epoch  13/100 | train Loss:    0.821 | train Accuracy    0.680 |\n",
      "-----------------------------------------------------------\n",
      "-----------------------------------------------------------\n",
      "| Epoch  13/100 | val Loss:    0.770 | val Accuracy    0.688 |\n",
      "-----------------------------------------------------------\n",
      "\n",
      "-----------------------------------------------------------\n",
      "| Epoch  14/100 | train Loss:    0.829 | train Accuracy    0.658 |\n",
      "-----------------------------------------------------------\n",
      "-----------------------------------------------------------\n",
      "| Epoch  14/100 | val Loss:    0.782 | val Accuracy    0.681 |\n",
      "-----------------------------------------------------------\n",
      "\n",
      "-----------------------------------------------------------\n",
      "| Epoch  15/100 | train Loss:    0.822 | train Accuracy    0.672 |\n",
      "-----------------------------------------------------------\n",
      "-----------------------------------------------------------\n",
      "| Epoch  15/100 | val Loss:    0.762 | val Accuracy    0.696 |\n",
      "-----------------------------------------------------------\n",
      "\n",
      "-----------------------------------------------------------\n",
      "| Epoch  16/100 | train Loss:    0.819 | train Accuracy    0.677 |\n",
      "-----------------------------------------------------------\n",
      "-----------------------------------------------------------\n",
      "| Epoch  16/100 | val Loss:    0.754 | val Accuracy    0.693 |\n",
      "-----------------------------------------------------------\n",
      "\n",
      "-----------------------------------------------------------\n",
      "| Epoch  17/100 | train Loss:    0.804 | train Accuracy    0.666 |\n",
      "-----------------------------------------------------------\n",
      "-----------------------------------------------------------\n",
      "| Epoch  17/100 | val Loss:    0.757 | val Accuracy    0.694 |\n",
      "-----------------------------------------------------------\n",
      "\n",
      "-----------------------------------------------------------\n",
      "| Epoch  18/100 | train Loss:    0.804 | train Accuracy    0.675 |\n",
      "-----------------------------------------------------------\n",
      "-----------------------------------------------------------\n",
      "| Epoch  18/100 | val Loss:    0.756 | val Accuracy    0.689 |\n",
      "-----------------------------------------------------------\n",
      "\n",
      "-----------------------------------------------------------\n",
      "| Epoch  19/100 | train Loss:    0.807 | train Accuracy    0.685 |\n",
      "-----------------------------------------------------------\n",
      "-----------------------------------------------------------\n",
      "| Epoch  19/100 | val Loss:    0.753 | val Accuracy    0.687 |\n",
      "-----------------------------------------------------------\n",
      "\n",
      "-----------------------------------------------------------\n",
      "| Epoch  20/100 | train Loss:    0.806 | train Accuracy    0.669 |\n",
      "-----------------------------------------------------------\n",
      "-----------------------------------------------------------\n",
      "| Epoch  20/100 | val Loss:    0.747 | val Accuracy    0.697 |\n",
      "-----------------------------------------------------------\n",
      "\n",
      "-----------------------------------------------------------\n",
      "| Epoch  21/100 | train Loss:    0.806 | train Accuracy    0.673 |\n",
      "-----------------------------------------------------------\n",
      "-----------------------------------------------------------\n",
      "| Epoch  21/100 | val Loss:    0.752 | val Accuracy    0.699 |\n",
      "-----------------------------------------------------------\n",
      "\n",
      "-----------------------------------------------------------\n",
      "| Epoch  22/100 | train Loss:    0.791 | train Accuracy    0.686 |\n",
      "-----------------------------------------------------------\n",
      "-----------------------------------------------------------\n",
      "| Epoch  22/100 | val Loss:    0.750 | val Accuracy    0.702 |\n",
      "-----------------------------------------------------------\n",
      "\n",
      "-----------------------------------------------------------\n",
      "| Epoch  23/100 | train Loss:    0.793 | train Accuracy    0.688 |\n",
      "-----------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------------------\n",
      "| Epoch  23/100 | val Loss:    0.753 | val Accuracy    0.689 |\n",
      "-----------------------------------------------------------\n",
      "\n",
      "-----------------------------------------------------------\n",
      "| Epoch  24/100 | train Loss:    0.788 | train Accuracy    0.683 |\n",
      "-----------------------------------------------------------\n",
      "-----------------------------------------------------------\n",
      "| Epoch  24/100 | val Loss:    0.745 | val Accuracy    0.692 |\n",
      "-----------------------------------------------------------\n",
      "\n",
      "-----------------------------------------------------------\n",
      "| Epoch  25/100 | train Loss:    0.785 | train Accuracy    0.693 |\n",
      "-----------------------------------------------------------\n",
      "-----------------------------------------------------------\n",
      "| Epoch  25/100 | val Loss:    0.745 | val Accuracy    0.699 |\n",
      "-----------------------------------------------------------\n",
      "\n",
      "-----------------------------------------------------------\n",
      "| Epoch  26/100 | train Loss:    0.789 | train Accuracy    0.683 |\n",
      "-----------------------------------------------------------\n",
      "-----------------------------------------------------------\n",
      "| Epoch  26/100 | val Loss:    0.743 | val Accuracy    0.701 |\n",
      "-----------------------------------------------------------\n",
      "\n",
      "-----------------------------------------------------------\n",
      "| Epoch  27/100 | train Loss:    0.791 | train Accuracy    0.682 |\n",
      "-----------------------------------------------------------\n",
      "-----------------------------------------------------------\n",
      "| Epoch  27/100 | val Loss:    0.753 | val Accuracy    0.701 |\n",
      "-----------------------------------------------------------\n",
      "\n",
      "-----------------------------------------------------------\n",
      "| Epoch  28/100 | train Loss:    0.771 | train Accuracy    0.692 |\n",
      "-----------------------------------------------------------\n",
      "-----------------------------------------------------------\n",
      "| Epoch  28/100 | val Loss:    0.742 | val Accuracy    0.704 |\n",
      "-----------------------------------------------------------\n",
      "\n",
      "-----------------------------------------------------------\n",
      "| Epoch  29/100 | train Loss:    0.764 | train Accuracy    0.686 |\n",
      "-----------------------------------------------------------\n",
      "-----------------------------------------------------------\n",
      "| Epoch  29/100 | val Loss:    0.736 | val Accuracy    0.702 |\n",
      "-----------------------------------------------------------\n",
      "\n",
      "-----------------------------------------------------------\n",
      "| Epoch  30/100 | train Loss:    0.764 | train Accuracy    0.702 |\n",
      "-----------------------------------------------------------\n",
      "-----------------------------------------------------------\n",
      "| Epoch  30/100 | val Loss:    0.740 | val Accuracy    0.711 |\n",
      "-----------------------------------------------------------\n",
      "\n",
      "-----------------------------------------------------------\n",
      "| Epoch  31/100 | train Loss:    0.773 | train Accuracy    0.701 |\n",
      "-----------------------------------------------------------\n",
      "-----------------------------------------------------------\n",
      "| Epoch  31/100 | val Loss:    0.747 | val Accuracy    0.689 |\n",
      "-----------------------------------------------------------\n",
      "\n",
      "-----------------------------------------------------------\n",
      "| Epoch  32/100 | train Loss:    0.787 | train Accuracy    0.686 |\n",
      "-----------------------------------------------------------\n",
      "-----------------------------------------------------------\n",
      "| Epoch  32/100 | val Loss:    0.737 | val Accuracy    0.702 |\n",
      "-----------------------------------------------------------\n",
      "\n",
      "-----------------------------------------------------------\n",
      "| Epoch  33/100 | train Loss:    0.779 | train Accuracy    0.697 |\n",
      "-----------------------------------------------------------\n",
      "-----------------------------------------------------------\n",
      "| Epoch  33/100 | val Loss:    0.748 | val Accuracy    0.697 |\n",
      "-----------------------------------------------------------\n",
      "\n",
      "-----------------------------------------------------------\n",
      "| Epoch  34/100 | train Loss:    0.765 | train Accuracy    0.696 |\n",
      "-----------------------------------------------------------\n",
      "-----------------------------------------------------------\n",
      "| Epoch  34/100 | val Loss:    0.745 | val Accuracy    0.697 |\n",
      "-----------------------------------------------------------\n",
      "\n",
      "-----------------------------------------------------------\n",
      "| Epoch  35/100 | train Loss:    0.764 | train Accuracy    0.707 |\n",
      "-----------------------------------------------------------\n",
      "-----------------------------------------------------------\n",
      "| Epoch  35/100 | val Loss:    0.737 | val Accuracy    0.706 |\n",
      "-----------------------------------------------------------\n",
      "\n",
      "-----------------------------------------------------------\n",
      "| Epoch  36/100 | train Loss:    0.755 | train Accuracy    0.704 |\n",
      "-----------------------------------------------------------\n",
      "-----------------------------------------------------------\n",
      "| Epoch  36/100 | val Loss:    0.752 | val Accuracy    0.698 |\n",
      "-----------------------------------------------------------\n",
      "\n",
      "-----------------------------------------------------------\n",
      "| Epoch  37/100 | train Loss:    0.751 | train Accuracy    0.700 |\n",
      "-----------------------------------------------------------\n",
      "-----------------------------------------------------------\n",
      "| Epoch  37/100 | val Loss:    0.737 | val Accuracy    0.701 |\n",
      "-----------------------------------------------------------\n",
      "\n",
      "-----------------------------------------------------------\n",
      "| Epoch  38/100 | train Loss:    0.755 | train Accuracy    0.703 |\n",
      "-----------------------------------------------------------\n",
      "-----------------------------------------------------------\n",
      "| Epoch  38/100 | val Loss:    0.736 | val Accuracy    0.701 |\n",
      "-----------------------------------------------------------\n",
      "\n",
      "-----------------------------------------------------------\n",
      "| Epoch  39/100 | train Loss:    0.765 | train Accuracy    0.686 |\n",
      "-----------------------------------------------------------\n",
      "-----------------------------------------------------------\n",
      "| Epoch  39/100 | val Loss:    0.734 | val Accuracy    0.714 |\n",
      "-----------------------------------------------------------\n",
      "\n",
      "-----------------------------------------------------------\n",
      "| Epoch  40/100 | train Loss:    0.751 | train Accuracy    0.702 |\n",
      "-----------------------------------------------------------\n",
      "-----------------------------------------------------------\n",
      "| Epoch  40/100 | val Loss:    0.743 | val Accuracy    0.702 |\n",
      "-----------------------------------------------------------\n",
      "\n",
      "-----------------------------------------------------------\n",
      "| Epoch  41/100 | train Loss:    0.756 | train Accuracy    0.693 |\n",
      "-----------------------------------------------------------\n",
      "-----------------------------------------------------------\n",
      "| Epoch  41/100 | val Loss:    0.731 | val Accuracy    0.706 |\n",
      "-----------------------------------------------------------\n",
      "\n",
      "-----------------------------------------------------------\n",
      "| Epoch  42/100 | train Loss:    0.765 | train Accuracy    0.705 |\n",
      "-----------------------------------------------------------\n",
      "-----------------------------------------------------------\n",
      "| Epoch  42/100 | val Loss:    0.738 | val Accuracy    0.702 |\n",
      "-----------------------------------------------------------\n",
      "\n",
      "-----------------------------------------------------------\n",
      "| Epoch  43/100 | train Loss:    0.730 | train Accuracy    0.707 |\n",
      "-----------------------------------------------------------\n",
      "-----------------------------------------------------------\n",
      "| Epoch  43/100 | val Loss:    0.725 | val Accuracy    0.715 |\n",
      "-----------------------------------------------------------\n",
      "\n",
      "-----------------------------------------------------------\n",
      "| Epoch  44/100 | train Loss:    0.737 | train Accuracy    0.709 |\n",
      "-----------------------------------------------------------\n",
      "-----------------------------------------------------------\n",
      "| Epoch  44/100 | val Loss:    0.735 | val Accuracy    0.704 |\n",
      "-----------------------------------------------------------\n",
      "\n",
      "-----------------------------------------------------------\n",
      "| Epoch  45/100 | train Loss:    0.748 | train Accuracy    0.701 |\n",
      "-----------------------------------------------------------\n",
      "-----------------------------------------------------------\n",
      "| Epoch  45/100 | val Loss:    0.733 | val Accuracy    0.710 |\n",
      "-----------------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------------------\n",
      "| Epoch  46/100 | train Loss:    0.744 | train Accuracy    0.711 |\n",
      "-----------------------------------------------------------\n",
      "-----------------------------------------------------------\n",
      "| Epoch  46/100 | val Loss:    0.746 | val Accuracy    0.702 |\n",
      "-----------------------------------------------------------\n",
      "\n",
      "-----------------------------------------------------------\n",
      "| Epoch  47/100 | train Loss:    0.722 | train Accuracy    0.707 |\n",
      "-----------------------------------------------------------\n",
      "-----------------------------------------------------------\n",
      "| Epoch  47/100 | val Loss:    0.725 | val Accuracy    0.718 |\n",
      "-----------------------------------------------------------\n",
      "\n",
      "-----------------------------------------------------------\n",
      "| Epoch  48/100 | train Loss:    0.742 | train Accuracy    0.704 |\n",
      "-----------------------------------------------------------\n",
      "-----------------------------------------------------------\n",
      "| Epoch  48/100 | val Loss:    0.720 | val Accuracy    0.714 |\n",
      "-----------------------------------------------------------\n",
      "\n",
      "-----------------------------------------------------------\n",
      "| Epoch  49/100 | train Loss:    0.732 | train Accuracy    0.709 |\n",
      "-----------------------------------------------------------\n",
      "-----------------------------------------------------------\n",
      "| Epoch  49/100 | val Loss:    0.719 | val Accuracy    0.713 |\n",
      "-----------------------------------------------------------\n",
      "\n",
      "-----------------------------------------------------------\n",
      "| Epoch  50/100 | train Loss:    0.729 | train Accuracy    0.707 |\n",
      "-----------------------------------------------------------\n",
      "-----------------------------------------------------------\n",
      "| Epoch  50/100 | val Loss:    0.728 | val Accuracy    0.712 |\n",
      "-----------------------------------------------------------\n",
      "\n",
      "-----------------------------------------------------------\n",
      "| Epoch  51/100 | train Loss:    0.720 | train Accuracy    0.709 |\n",
      "-----------------------------------------------------------\n",
      "-----------------------------------------------------------\n",
      "| Epoch  51/100 | val Loss:    0.722 | val Accuracy    0.711 |\n",
      "-----------------------------------------------------------\n",
      "\n",
      "-----------------------------------------------------------\n",
      "| Epoch  52/100 | train Loss:    0.705 | train Accuracy    0.720 |\n",
      "-----------------------------------------------------------\n",
      "-----------------------------------------------------------\n",
      "| Epoch  52/100 | val Loss:    0.728 | val Accuracy    0.711 |\n",
      "-----------------------------------------------------------\n",
      "\n",
      "-----------------------------------------------------------\n",
      "| Epoch  53/100 | train Loss:    0.716 | train Accuracy    0.708 |\n",
      "-----------------------------------------------------------\n",
      "-----------------------------------------------------------\n",
      "| Epoch  53/100 | val Loss:    0.716 | val Accuracy    0.718 |\n",
      "-----------------------------------------------------------\n",
      "\n",
      "-----------------------------------------------------------\n",
      "| Epoch  54/100 | train Loss:    0.724 | train Accuracy    0.712 |\n",
      "-----------------------------------------------------------\n",
      "-----------------------------------------------------------\n",
      "| Epoch  54/100 | val Loss:    0.718 | val Accuracy    0.715 |\n",
      "-----------------------------------------------------------\n",
      "\n",
      "-----------------------------------------------------------\n",
      "| Epoch  55/100 | train Loss:    0.709 | train Accuracy    0.719 |\n",
      "-----------------------------------------------------------\n",
      "-----------------------------------------------------------\n",
      "| Epoch  55/100 | val Loss:    0.722 | val Accuracy    0.721 |\n",
      "-----------------------------------------------------------\n",
      "\n",
      "-----------------------------------------------------------\n",
      "| Epoch  56/100 | train Loss:    0.727 | train Accuracy    0.715 |\n",
      "-----------------------------------------------------------\n",
      "-----------------------------------------------------------\n",
      "| Epoch  56/100 | val Loss:    0.725 | val Accuracy    0.718 |\n",
      "-----------------------------------------------------------\n",
      "\n",
      "-----------------------------------------------------------\n",
      "| Epoch  57/100 | train Loss:    0.724 | train Accuracy    0.708 |\n",
      "-----------------------------------------------------------\n",
      "-----------------------------------------------------------\n",
      "| Epoch  57/100 | val Loss:    0.720 | val Accuracy    0.718 |\n",
      "-----------------------------------------------------------\n",
      "\n",
      "-----------------------------------------------------------\n",
      "| Epoch  58/100 | train Loss:    0.711 | train Accuracy    0.719 |\n",
      "-----------------------------------------------------------\n",
      "-----------------------------------------------------------\n",
      "| Epoch  58/100 | val Loss:    0.710 | val Accuracy    0.723 |\n",
      "-----------------------------------------------------------\n",
      "\n",
      "-----------------------------------------------------------\n",
      "| Epoch  59/100 | train Loss:    0.700 | train Accuracy    0.724 |\n",
      "-----------------------------------------------------------\n",
      "-----------------------------------------------------------\n",
      "| Epoch  59/100 | val Loss:    0.725 | val Accuracy    0.720 |\n",
      "-----------------------------------------------------------\n",
      "\n",
      "-----------------------------------------------------------\n",
      "| Epoch  60/100 | train Loss:    0.698 | train Accuracy    0.722 |\n",
      "-----------------------------------------------------------\n",
      "-----------------------------------------------------------\n",
      "| Epoch  60/100 | val Loss:    0.728 | val Accuracy    0.719 |\n",
      "-----------------------------------------------------------\n",
      "\n",
      "-----------------------------------------------------------\n",
      "| Epoch  61/100 | train Loss:    0.693 | train Accuracy    0.719 |\n",
      "-----------------------------------------------------------\n",
      "-----------------------------------------------------------\n",
      "| Epoch  61/100 | val Loss:    0.705 | val Accuracy    0.718 |\n",
      "-----------------------------------------------------------\n",
      "\n",
      "-----------------------------------------------------------\n",
      "| Epoch  62/100 | train Loss:    0.714 | train Accuracy    0.708 |\n",
      "-----------------------------------------------------------\n",
      "-----------------------------------------------------------\n",
      "| Epoch  62/100 | val Loss:    0.718 | val Accuracy    0.715 |\n",
      "-----------------------------------------------------------\n",
      "\n",
      "-----------------------------------------------------------\n",
      "| Epoch  63/100 | train Loss:    0.684 | train Accuracy    0.736 |\n",
      "-----------------------------------------------------------\n",
      "-----------------------------------------------------------\n",
      "| Epoch  63/100 | val Loss:    0.705 | val Accuracy    0.727 |\n",
      "-----------------------------------------------------------\n",
      "\n",
      "-----------------------------------------------------------\n",
      "| Epoch  64/100 | train Loss:    0.700 | train Accuracy    0.721 |\n",
      "-----------------------------------------------------------\n",
      "-----------------------------------------------------------\n",
      "| Epoch  64/100 | val Loss:    0.707 | val Accuracy    0.720 |\n",
      "-----------------------------------------------------------\n",
      "\n",
      "-----------------------------------------------------------\n",
      "| Epoch  65/100 | train Loss:    0.707 | train Accuracy    0.724 |\n",
      "-----------------------------------------------------------\n",
      "-----------------------------------------------------------\n",
      "| Epoch  65/100 | val Loss:    0.720 | val Accuracy    0.718 |\n",
      "-----------------------------------------------------------\n",
      "\n",
      "-----------------------------------------------------------\n",
      "| Epoch  66/100 | train Loss:    0.702 | train Accuracy    0.714 |\n",
      "-----------------------------------------------------------\n",
      "-----------------------------------------------------------\n",
      "| Epoch  66/100 | val Loss:    0.715 | val Accuracy    0.721 |\n",
      "-----------------------------------------------------------\n",
      "\n",
      "-----------------------------------------------------------\n",
      "| Epoch  67/100 | train Loss:    0.704 | train Accuracy    0.726 |\n",
      "-----------------------------------------------------------\n",
      "-----------------------------------------------------------\n",
      "| Epoch  67/100 | val Loss:    0.704 | val Accuracy    0.727 |\n",
      "-----------------------------------------------------------\n",
      "\n",
      "-----------------------------------------------------------\n",
      "| Epoch  68/100 | train Loss:    0.685 | train Accuracy    0.732 |\n",
      "-----------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------------------\n",
      "| Epoch  68/100 | val Loss:    0.712 | val Accuracy    0.718 |\n",
      "-----------------------------------------------------------\n",
      "\n",
      "-----------------------------------------------------------\n",
      "| Epoch  69/100 | train Loss:    0.687 | train Accuracy    0.733 |\n",
      "-----------------------------------------------------------\n",
      "-----------------------------------------------------------\n",
      "| Epoch  69/100 | val Loss:    0.710 | val Accuracy    0.716 |\n",
      "-----------------------------------------------------------\n",
      "\n",
      "-----------------------------------------------------------\n",
      "| Epoch  70/100 | train Loss:    0.695 | train Accuracy    0.728 |\n",
      "-----------------------------------------------------------\n",
      "-----------------------------------------------------------\n",
      "| Epoch  70/100 | val Loss:    0.723 | val Accuracy    0.722 |\n",
      "-----------------------------------------------------------\n",
      "\n",
      "-----------------------------------------------------------\n",
      "| Epoch  71/100 | train Loss:    0.674 | train Accuracy    0.734 |\n",
      "-----------------------------------------------------------\n",
      "-----------------------------------------------------------\n",
      "| Epoch  71/100 | val Loss:    0.702 | val Accuracy    0.728 |\n",
      "-----------------------------------------------------------\n",
      "\n",
      "-----------------------------------------------------------\n",
      "| Epoch  72/100 | train Loss:    0.674 | train Accuracy    0.736 |\n",
      "-----------------------------------------------------------\n",
      "-----------------------------------------------------------\n",
      "| Epoch  72/100 | val Loss:    0.711 | val Accuracy    0.724 |\n",
      "-----------------------------------------------------------\n",
      "\n",
      "-----------------------------------------------------------\n",
      "| Epoch  73/100 | train Loss:    0.663 | train Accuracy    0.744 |\n",
      "-----------------------------------------------------------\n",
      "-----------------------------------------------------------\n",
      "| Epoch  73/100 | val Loss:    0.708 | val Accuracy    0.725 |\n",
      "-----------------------------------------------------------\n",
      "\n",
      "-----------------------------------------------------------\n",
      "| Epoch  74/100 | train Loss:    0.659 | train Accuracy    0.738 |\n",
      "-----------------------------------------------------------\n",
      "-----------------------------------------------------------\n",
      "| Epoch  74/100 | val Loss:    0.706 | val Accuracy    0.722 |\n",
      "-----------------------------------------------------------\n",
      "\n",
      "-----------------------------------------------------------\n",
      "| Epoch  75/100 | train Loss:    0.646 | train Accuracy    0.758 |\n",
      "-----------------------------------------------------------\n",
      "-----------------------------------------------------------\n",
      "| Epoch  75/100 | val Loss:    0.708 | val Accuracy    0.726 |\n",
      "-----------------------------------------------------------\n",
      "\n",
      "-----------------------------------------------------------\n",
      "| Epoch  76/100 | train Loss:    0.660 | train Accuracy    0.738 |\n",
      "-----------------------------------------------------------\n",
      "-----------------------------------------------------------\n",
      "| Epoch  76/100 | val Loss:    0.708 | val Accuracy    0.725 |\n",
      "-----------------------------------------------------------\n",
      "\n",
      "-----------------------------------------------------------\n",
      "| Epoch  77/100 | train Loss:    0.665 | train Accuracy    0.737 |\n",
      "-----------------------------------------------------------\n",
      "-----------------------------------------------------------\n",
      "| Epoch  77/100 | val Loss:    0.709 | val Accuracy    0.730 |\n",
      "-----------------------------------------------------------\n",
      "\n",
      "-----------------------------------------------------------\n",
      "| Epoch  78/100 | train Loss:    0.653 | train Accuracy    0.744 |\n",
      "-----------------------------------------------------------\n",
      "-----------------------------------------------------------\n",
      "| Epoch  78/100 | val Loss:    0.714 | val Accuracy    0.723 |\n",
      "-----------------------------------------------------------\n",
      "\n",
      "-----------------------------------------------------------\n",
      "| Epoch  79/100 | train Loss:    0.665 | train Accuracy    0.739 |\n",
      "-----------------------------------------------------------\n",
      "-----------------------------------------------------------\n",
      "| Epoch  79/100 | val Loss:    0.714 | val Accuracy    0.716 |\n",
      "-----------------------------------------------------------\n",
      "\n",
      "-----------------------------------------------------------\n",
      "| Epoch  80/100 | train Loss:    0.663 | train Accuracy    0.750 |\n",
      "-----------------------------------------------------------\n",
      "-----------------------------------------------------------\n",
      "| Epoch  80/100 | val Loss:    0.710 | val Accuracy    0.728 |\n",
      "-----------------------------------------------------------\n",
      "\n",
      "-----------------------------------------------------------\n",
      "| Epoch  81/100 | train Loss:    0.641 | train Accuracy    0.749 |\n",
      "-----------------------------------------------------------\n",
      "-----------------------------------------------------------\n",
      "| Epoch  81/100 | val Loss:    0.704 | val Accuracy    0.728 |\n",
      "-----------------------------------------------------------\n",
      "\n",
      "-----------------------------------------------------------\n",
      "| Epoch  82/100 | train Loss:    0.652 | train Accuracy    0.747 |\n",
      "-----------------------------------------------------------\n",
      "-----------------------------------------------------------\n",
      "| Epoch  82/100 | val Loss:    0.704 | val Accuracy    0.728 |\n",
      "-----------------------------------------------------------\n",
      "\n",
      "-----------------------------------------------------------\n",
      "| Epoch  83/100 | train Loss:    0.640 | train Accuracy    0.743 |\n",
      "-----------------------------------------------------------\n",
      "-----------------------------------------------------------\n",
      "| Epoch  83/100 | val Loss:    0.707 | val Accuracy    0.726 |\n",
      "-----------------------------------------------------------\n",
      "\n",
      "-----------------------------------------------------------\n",
      "| Epoch  84/100 | train Loss:    0.632 | train Accuracy    0.746 |\n",
      "-----------------------------------------------------------\n",
      "-----------------------------------------------------------\n",
      "| Epoch  84/100 | val Loss:    0.708 | val Accuracy    0.717 |\n",
      "-----------------------------------------------------------\n",
      "\n",
      "-----------------------------------------------------------\n",
      "| Epoch  85/100 | train Loss:    0.659 | train Accuracy    0.743 |\n",
      "-----------------------------------------------------------\n",
      "-----------------------------------------------------------\n",
      "| Epoch  85/100 | val Loss:    0.699 | val Accuracy    0.729 |\n",
      "-----------------------------------------------------------\n",
      "\n",
      "-----------------------------------------------------------\n",
      "| Epoch  86/100 | train Loss:    0.649 | train Accuracy    0.747 |\n",
      "-----------------------------------------------------------\n",
      "-----------------------------------------------------------\n",
      "| Epoch  86/100 | val Loss:    0.688 | val Accuracy    0.734 |\n",
      "-----------------------------------------------------------\n",
      "\n",
      "-----------------------------------------------------------\n",
      "| Epoch  87/100 | train Loss:    0.631 | train Accuracy    0.758 |\n",
      "-----------------------------------------------------------\n",
      "-----------------------------------------------------------\n",
      "| Epoch  87/100 | val Loss:    0.703 | val Accuracy    0.728 |\n",
      "-----------------------------------------------------------\n",
      "\n",
      "-----------------------------------------------------------\n",
      "| Epoch  88/100 | train Loss:    0.624 | train Accuracy    0.756 |\n",
      "-----------------------------------------------------------\n",
      "-----------------------------------------------------------\n",
      "| Epoch  88/100 | val Loss:    0.697 | val Accuracy    0.732 |\n",
      "-----------------------------------------------------------\n",
      "\n",
      "-----------------------------------------------------------\n",
      "| Epoch  89/100 | train Loss:    0.632 | train Accuracy    0.754 |\n",
      "-----------------------------------------------------------\n",
      "-----------------------------------------------------------\n",
      "| Epoch  89/100 | val Loss:    0.708 | val Accuracy    0.722 |\n",
      "-----------------------------------------------------------\n",
      "\n",
      "-----------------------------------------------------------\n",
      "| Epoch  90/100 | train Loss:    0.629 | train Accuracy    0.750 |\n",
      "-----------------------------------------------------------\n",
      "-----------------------------------------------------------\n",
      "| Epoch  90/100 | val Loss:    0.694 | val Accuracy    0.738 |\n",
      "-----------------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------------------\n",
      "| Epoch  91/100 | train Loss:    0.623 | train Accuracy    0.753 |\n",
      "-----------------------------------------------------------\n",
      "-----------------------------------------------------------\n",
      "| Epoch  91/100 | val Loss:    0.689 | val Accuracy    0.729 |\n",
      "-----------------------------------------------------------\n",
      "\n",
      "-----------------------------------------------------------\n",
      "| Epoch  92/100 | train Loss:    0.634 | train Accuracy    0.749 |\n",
      "-----------------------------------------------------------\n",
      "-----------------------------------------------------------\n",
      "| Epoch  92/100 | val Loss:    0.693 | val Accuracy    0.724 |\n",
      "-----------------------------------------------------------\n",
      "\n",
      "-----------------------------------------------------------\n",
      "| Epoch  93/100 | train Loss:    0.638 | train Accuracy    0.741 |\n",
      "-----------------------------------------------------------\n",
      "-----------------------------------------------------------\n",
      "| Epoch  93/100 | val Loss:    0.691 | val Accuracy    0.733 |\n",
      "-----------------------------------------------------------\n",
      "\n",
      "-----------------------------------------------------------\n",
      "| Epoch  94/100 | train Loss:    0.625 | train Accuracy    0.759 |\n",
      "-----------------------------------------------------------\n",
      "-----------------------------------------------------------\n",
      "| Epoch  94/100 | val Loss:    0.692 | val Accuracy    0.729 |\n",
      "-----------------------------------------------------------\n",
      "\n",
      "-----------------------------------------------------------\n",
      "| Epoch  95/100 | train Loss:    0.622 | train Accuracy    0.763 |\n",
      "-----------------------------------------------------------\n",
      "-----------------------------------------------------------\n",
      "| Epoch  95/100 | val Loss:    0.695 | val Accuracy    0.731 |\n",
      "-----------------------------------------------------------\n",
      "\n",
      "-----------------------------------------------------------\n",
      "| Epoch  96/100 | train Loss:    0.613 | train Accuracy    0.762 |\n",
      "-----------------------------------------------------------\n",
      "-----------------------------------------------------------\n",
      "| Epoch  96/100 | val Loss:    0.703 | val Accuracy    0.724 |\n",
      "-----------------------------------------------------------\n",
      "\n",
      "-----------------------------------------------------------\n",
      "| Epoch  97/100 | train Loss:    0.609 | train Accuracy    0.766 |\n",
      "-----------------------------------------------------------\n",
      "-----------------------------------------------------------\n",
      "| Epoch  97/100 | val Loss:    0.697 | val Accuracy    0.721 |\n",
      "-----------------------------------------------------------\n",
      "\n",
      "-----------------------------------------------------------\n",
      "| Epoch  98/100 | train Loss:    0.610 | train Accuracy    0.766 |\n",
      "-----------------------------------------------------------\n",
      "-----------------------------------------------------------\n",
      "| Epoch  98/100 | val Loss:    0.697 | val Accuracy    0.713 |\n",
      "-----------------------------------------------------------\n",
      "\n",
      "-----------------------------------------------------------\n",
      "| Epoch  99/100 | train Loss:    0.620 | train Accuracy    0.755 |\n",
      "-----------------------------------------------------------\n",
      "-----------------------------------------------------------\n",
      "| Epoch  99/100 | val Loss:    0.700 | val Accuracy    0.732 |\n",
      "-----------------------------------------------------------\n",
      "\n",
      "-----------------------------------------------------------\n",
      "| Epoch 100/100 | train Loss:    0.616 | train Accuracy    0.757 |\n",
      "-----------------------------------------------------------\n",
      "-----------------------------------------------------------\n",
      "| Epoch 100/100 | val Loss:    0.683 | val Accuracy    0.735 |\n",
      "-----------------------------------------------------------\n",
      "\n",
      "Training Complete in 203m 3s\n",
      "Best Validation Accuracy: 0.7382\n"
     ]
    }
   ],
   "source": [
    "result_dict = {}\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "model, hist = train_model(model, dataloaders_dict, criterion, optimizer_ft, epochs = 100, result_dict=result_dict,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1210c389",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for x in range(1, 1062):\n",
    "#     if 1062%x == 0:\n",
    "#         print(f'rem: {1062%x} --> {x}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d71a47d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "201191e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_copy = model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f73dce17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CSV_NAME = \"100epochs_lr_0.01.csv\"\n",
    "# PATH = \"100_epochs_lr_0.01.pth\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ebf678d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5e153ca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_dict2 = result_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1ee6b981",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_dict2['Epoch'] = list(dict.fromkeys(result_dict2['Epoch']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9ec53c5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_dict2['train Accuracy'] = list(acc.item() for acc in result_dict2['train Accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "14361cc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_dict2['val Accuracy'] = list(acc.item() for acc in result_dict2['val Accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "301f8791",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame.from_dict(result_dict2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f9357726",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Epoch</th>\n",
       "      <th>train Accuracy</th>\n",
       "      <th>train Loss</th>\n",
       "      <th>val Accuracy</th>\n",
       "      <th>val Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.425479</td>\n",
       "      <td>1.256091</td>\n",
       "      <td>0.494350</td>\n",
       "      <td>1.155301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.542516</td>\n",
       "      <td>1.111588</td>\n",
       "      <td>0.581921</td>\n",
       "      <td>1.006653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.600565</td>\n",
       "      <td>0.989055</td>\n",
       "      <td>0.679849</td>\n",
       "      <td>0.861571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.617195</td>\n",
       "      <td>0.946398</td>\n",
       "      <td>0.660075</td>\n",
       "      <td>0.869395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.632256</td>\n",
       "      <td>0.908349</td>\n",
       "      <td>0.669492</td>\n",
       "      <td>0.840908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>96</td>\n",
       "      <td>0.761531</td>\n",
       "      <td>0.613430</td>\n",
       "      <td>0.724105</td>\n",
       "      <td>0.703347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>97</td>\n",
       "      <td>0.765924</td>\n",
       "      <td>0.609029</td>\n",
       "      <td>0.721281</td>\n",
       "      <td>0.697134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>98</td>\n",
       "      <td>0.765610</td>\n",
       "      <td>0.609600</td>\n",
       "      <td>0.712806</td>\n",
       "      <td>0.696553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>99</td>\n",
       "      <td>0.754942</td>\n",
       "      <td>0.620260</td>\n",
       "      <td>0.731638</td>\n",
       "      <td>0.700342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>100</td>\n",
       "      <td>0.757138</td>\n",
       "      <td>0.615630</td>\n",
       "      <td>0.735405</td>\n",
       "      <td>0.682889</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Epoch  train Accuracy  train Loss  val Accuracy  val Loss\n",
       "0       1        0.425479    1.256091      0.494350  1.155301\n",
       "1       2        0.542516    1.111588      0.581921  1.006653\n",
       "2       3        0.600565    0.989055      0.679849  0.861571\n",
       "3       4        0.617195    0.946398      0.660075  0.869395\n",
       "4       5        0.632256    0.908349      0.669492  0.840908\n",
       "..    ...             ...         ...           ...       ...\n",
       "95     96        0.761531    0.613430      0.724105  0.703347\n",
       "96     97        0.765924    0.609029      0.721281  0.697134\n",
       "97     98        0.765610    0.609600      0.712806  0.696553\n",
       "98     99        0.754942    0.620260      0.731638  0.700342\n",
       "99    100        0.757138    0.615630      0.735405  0.682889\n",
       "\n",
       "[100 rows x 5 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3eee472d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(CSV_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "60e9e350",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = MultiModalGarbageModel(num_classes, language_model, vision_model, language_model_name,\n",
    "                                          vision_model_name, out_features)\n",
    "model.load_state_dict(torch.load(PATH))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deeb1fbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imports for confusion matrix.\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "import seaborn as sns\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c874dee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(test_loader):\n",
    "\n",
    "    #actual vs predicted label list for confusion matrix\n",
    "    actual_label = []\n",
    "    predict_label = []\n",
    "\n",
    "    #For incorrect lists.\n",
    "    incorrect_samples = []\n",
    "    incorrect_labels = []\n",
    "    incorrect_pred_labels = []\n",
    "    incorrect_filenames = []\n",
    "\n",
    "    # Test loop\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad(): # inputs, labels, in_ids, att_mask\n",
    "        for batch in test_loader:\n",
    "            image_input, labels, input_ids, attention_mask = batch\n",
    "            input_ids, attention_mask, labels = input_ids.to(device), attention_mask.to(device), labels.to(device)\n",
    "            image_input = image_input.to(device)\n",
    "            #add the actual label for confusion matrix\n",
    "            actual_label.extend(labels.cpu().numpy())\n",
    "            \n",
    "            outputs = model(image_input, input_ids, attention_mask=attention_mask)\n",
    "            logits = outputs\n",
    "            _, predicted = torch.max(logits, 1)\n",
    "            #add predicted label for confusion matrix\n",
    "            predict_label.extend(labels.cpu().numpy())\n",
    "            \n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "            #For each batch, store a mask of incorrect indices, then append the info to the lists\n",
    "            incorrect_index = ((predicted == labels.view_as(predicted)) == False).view(-1)\n",
    "            incorrect_samples.append(image_input[incorrect_index].cpu().numpy())\n",
    "            incorrect_labels.append(labels[incorrect_index].cpu().numpy())\n",
    "            incorrect_pred_labels.append(predicted[incorrect_index].cpu().numpy())\n",
    "\n",
    "            #Get filenames using batch decode\n",
    "            decoded_names = tokenizer.batch_decode(input_ids, skip_special_tokens=True, clean_up_tokenization_spaces=True)\n",
    "            incorrect_filenames_by_batch = []\n",
    "\n",
    "            #Store in incorrect_filenames based on the incorrect_index mask\n",
    "            for i in range(len(incorrect_index)):\n",
    "                if incorrect_index[i]:\n",
    "                    incorrect_filenames_by_batch.append(decoded_names[i])\n",
    "            incorrect_filenames.append(incorrect_filenames_by_batch)\n",
    "\n",
    "    #Show the confusion matrix at the end.\n",
    "    conf_matrix = confusion_matrix(actual_label, predict_label)\n",
    "    ConfusionMatrixDisplay(conf_matrix).plot()\n",
    "\n",
    "    #For misclassified labels\n",
    "    fig = plt.figure(figsize=(8, 10))\n",
    "\n",
    "    #Loop through first entry in each batch [idx][0]\n",
    "    for idx in np.arange(5):\n",
    "        ax = fig.add_subplot(3, 2, idx+1, xticks=[], yticks=[])\n",
    "        misclassified_data = incorrect_samples[idx][0]\n",
    "        misclassified_data = misclassified_data/2 + 0.5\n",
    "        msc_image = misclassified_data\n",
    "        msc_image = np.clip(msc_image, 0, 1)\n",
    "        msc_image = msc_image.T\n",
    "        plt.imshow(np.squeeze(msc_image))\n",
    "        plt.title('actual_label: {0} predicted_label: {1}\\n object name: {2} '\n",
    "                  .format(incorrect_labels[idx][0], incorrect_pred_labels[idx][0], incorrect_filenames[idx][0]), wrap=True)\n",
    "        \n",
    "    plt.show()\n",
    "            \n",
    "    return correct/total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "787a541d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7433712121212122"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = evaluate(test_dataloader)\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d36e0a8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_copy.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8c5c83e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#lr = 0.01 - test acc = 0.6875\n",
    "#lr = 0.001 - test acc = 0.82197\n",
    "#lr = 0.0001 - test acc = 0.80208\n",
    "#lr = 0.00001 - test acc = 0.58049\n",
    "\n",
    "#lr = 0.001 - test acc = 0.81345 (batch_size = 32)\n",
    "#lr = 0.001 - test acc = 0.6981 (batch_size = 8)\n",
    "\n",
    "#lr = 0.001 - test acc = 0.74337(mobilenet-bert)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
